{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![copcarimage](https://timelinecovers.pro/facebook-cover/download/police-car-in-action-facebook-cover.jpg)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:0;color:orange;background-color:orange\">\n",
    "<center> <span style=\"font-size: 26px;\"> Unsupervised Machine Learning Assignment </span> </center>\n",
    "\n",
    "<span style=\"font-size: 16px;\">\n",
    "\n",
    "+ Session: **Unsupervised Machine Learning **\n",
    "+ Assignment: ***Crimes in Boston***\n",
    "+ Submitted by: **Paul Jason Jumalon**\n",
    "+ Submitted to: **Christa Santos**\n",
    "\n",
    "\n",
    "\n",
    "</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr style=\"height:5px;border-width:0;color:orange;background-color:orange\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # Series and DataFrames\n",
    "\n",
    "# import libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from prophet import Prophet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('crime.csv', encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_df = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select_dtypes(include=['object']).describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop_duplicates(subset=\"INCIDENT_NUMBER\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select_dtypes(include=['number']).describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select_dtypes(include=['object']).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.select_dtypes(include=['number']).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual graph of Null values in Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"SHOOTING\"].fillna(\"N\", inplace = True)\n",
    "df1[\"DISTRICT\"].fillna(\"Unknown\", inplace = True)\n",
    "df1[\"STREET\"].fillna(\"Unknown\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Lat'] = df1['Lat'].replace(np.nan, df1['Lat'].median())\n",
    "df1['Long'] = df1['Long'].replace(np.nan, df1['Long'].median())\n",
    "df1['Lat'] = df1['Lat'].replace(-1, df1['Lat'].median())\n",
    "df1['Long'] = df1['Long'].replace(-1, df1['Long'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All NULLs / Duplicates and Longitude / Lattitude Outliers have been treated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the data, data visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['OFFENSE_CODE_GROUP'].value_counts(dropna=np.False_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mpldatacursor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crimes by Type and Location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = df1['OFFENSE_CODE_GROUP'].value_counts().head(3).index\n",
    "\n",
    "sns.countplot(data = df1, x = 'OFFENSE_CODE_GROUP', hue = 'DISTRICT', order = sort, palette = 'rainbow')\n",
    "plt.title('Top 3 Crime Group by District')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,8)\n",
    "plt.legend(loc='upper right', prop={'size': 7});\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['DISTRICT'].value_counts(dropna=np.False_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = df1['DISTRICT'].value_counts().head(3).index\n",
    "\n",
    "sns.countplot(data = df1, x = 'DISTRICT', hue = 'OFFENSE_CODE_GROUP', order = sort, palette = 'rainbow')\n",
    "plt.title('Districts with Highest Crime rates by Day ')\n",
    "plt.title('Top 3 District by Crime Group')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(35,8)\n",
    "\n",
    "plt.legend(loc= 'upper right', prop={'size': 7});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = df1['DISTRICT'].value_counts().head(5).index\n",
    "plt.style.use('bmh')\n",
    "\n",
    "sns.countplot(data = df1, x = 'DISTRICT', hue = 'DAY_OF_WEEK', order = sort, palette = 'rainbow')\n",
    "plt.title('Districts with Highest Crime rates by Day of the week ')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,8)\n",
    "plt.legend(loc='upper right', prop={'size': 7});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = df1['OFFENSE_CODE_GROUP'].value_counts().index\n",
    "\n",
    "sns.countplot(data = df1, x = 'OFFENSE_CODE_GROUP', order = sort, palette = 'rainbow')\n",
    "plt.title('Crime types in Boston,Jun 2015 to Sep 2018')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18,8)\n",
    "\n",
    "plt.xticks(\n",
    "    rotation=90,\n",
    "    horizontalalignment='right',\n",
    "    fontweight='light',\n",
    "    fontsize='medium',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crimes with Shootings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crimeswthshooting = pd.DataFrame(data =(df1.groupby(['DISTRICT','SHOOTING']).count()[['INCIDENT_NUMBER']]).reset_index().values, columns=[\"DISTRICT\",\"SHOOTING\",\"CRIME COUNT\",]).sort_values('SHOOTING').reset_index(drop=True)\n",
    "ShootingbyCrime = pd.DataFrame(data =(df1.groupby(['OFFENSE_CODE_GROUP','SHOOTING']).count()[['INCIDENT_NUMBER']]).reset_index().values, columns=['OFFENSE_CODE_GROUP',\"SHOOTING\",\"CRIME COUNT\",]).sort_values('SHOOTING').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(Crimeswthshooting, values='CRIME COUNT', names='SHOOTING',title='Crimes with SHOOTINGS')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESELECT SHOOTING = N, in Legend, to see exact Shooting numbers by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(Crimeswthshooting, x='DISTRICT', y=\"CRIME COUNT\", color=\"SHOOTING\",barmode='group', title='Crimes per districts with SHOOTINGS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESELECT SHOOTING = N, in Legend, to see exact Shooting numbers by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(Crimeswthshooting, x='DISTRICT', y=\"CRIME COUNT\", color=\"SHOOTING\",barmode='group', title='Crimes per districts with SHOOTINGS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESELECT SHOOTING = N, in Legend, to see exact Shooting numbers by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(ShootingbyCrime, x='OFFENSE_CODE_GROUP', y=\"CRIME COUNT\", color=\"SHOOTING\",barmode='group', title='Crimes per districts with SHOOTINGS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the data over different time breakdowns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "ucrbyday = pd.DataFrame(data =(df1.groupby(['DAY_OF_WEEK','UCR_PART']).count()[['INCIDENT_NUMBER']]).reset_index().values, columns=[\"DAY\",\"UCR_PART\",\"CRIME COUNT\"]).sort_values('DAY').reset_index(drop=True)\n",
    "ucrbyday['DAY'] = pd.Categorical(ucrbyday['DAY'], categories=m, ordered=True)\n",
    "ucrbyday = ucrbyday.sort_values('DAY').reset_index(drop=True)\n",
    "ucrbydhour = pd.DataFrame(data =(df1.groupby(['HOUR','UCR_PART']).count()[['INCIDENT_NUMBER']]).reset_index().values, columns=[\"HOUR\",\"UCR_PART\",\"CRIME COUNT\"]).sort_values('HOUR').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(ucrbyday, x='DAY', y=\"CRIME COUNT\", color=\"UCR_PART\",title='Crime counts by Day across UCR Parts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(ucrbyday, x='UCR_PART', y='CRIME COUNT', color = 'DAY',title='Crime counts by Day across UCR Parts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "\n",
    "df1['OCCURRED_ON_DATE'] = pd.to_datetime(df1['OCCURRED_ON_DATE'])\n",
    "\n",
    "# Creating two new features\n",
    "df1[\"Quarter\"] = df1[\"OCCURRED_ON_DATE\"].dt.quarter\n",
    "df1[\"Weekofyear\"] = df1[\"OCCURRED_ON_DATE\"].dt.weekofyear\n",
    "\n",
    "# Convert into categorical data type\n",
    "df1[\"Quarter\"] = df1[\"Quarter\"].astype(\"category\")\n",
    "df1[\"Weekofyear\"] = df1[\"Weekofyear\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_year = pd.DataFrame(data=df1['YEAR'].value_counts().reset_index().values, columns=[\"YEAR\",\"CRIME COUNT\"]).sort_values('YEAR').reset_index(drop=True)\n",
    "crimes_per_month = pd.DataFrame(data=df1['MONTH'].value_counts().reset_index().values, columns=[\"MONTH\",\"CRIME COUNT\"]).sort_values('MONTH').reset_index(drop=True)\n",
    "crimes_per_day = pd.DataFrame(data=df1['DAY_OF_WEEK'].value_counts().reset_index().values, columns=[\"DAY\",\"CRIME COUNT\"])\n",
    "crimes_per_day[\"DAY\"] = pd.Categorical(crimes_per_day['DAY'], categories=m, ordered=True)\n",
    "crimes_per_day = crimes_per_day.sort_values('DAY').reset_index(drop=True)\n",
    "crimes_per_hour = pd.DataFrame(data=df1['HOUR'].value_counts().reset_index().values, columns=[\"HOUR\",\"CRIME COUNT\"]).sort_values('HOUR').reset_index(drop=True)\n",
    "crimes_per_Weekofyear = pd.DataFrame(data=df1['Weekofyear'].value_counts().reset_index().values, columns=[\"Weekofyear\",\"CRIME COUNT\"])\n",
    "crimes_per_Quarter = pd.DataFrame(data=df1['Quarter'].value_counts().reset_index().values, columns=[\"Quarter\",\"CRIME COUNT\"]).sort_values('CRIME COUNT',ascending=False).reset_index(drop=True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offense_code_count = pd.DataFrame(df1['OFFENSE_CODE_GROUP'].value_counts().reset_index().values, columns=[\"OFFENSE_CODE_GROUP'\",\"CRIME COUNT\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"},{\"type\": \"scatter\"}],[{\"type\": \"scatter\"},{\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n",
    "    subplot_titles=(\"Number of crimes per year\", \"Number of crimes per month\", \"Number of crimes per day\", \"Number of crimes per hour\",\"Number of crimes per Week of year\",\"Number of crimes per Quarter\"))\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x=crimes_per_year[\"YEAR\"], y=crimes_per_year[\"CRIME COUNT\"]), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=crimes_per_month[\"MONTH\"], y=crimes_per_month[\"CRIME COUNT\"]), row=1, col=2)\n",
    "fig.add_trace(go.Bar(x=crimes_per_day[\"DAY\"], y=crimes_per_day[\"CRIME COUNT\"]), row=1, col=3)\n",
    "fig.add_trace(go.Scatter(x=crimes_per_hour[\"HOUR\"], y=crimes_per_hour[\"CRIME COUNT\"]), row=2, col=1)\n",
    "fig.add_trace(go.Bar(x=crimes_per_Weekofyear[\"Weekofyear\"], y=crimes_per_Weekofyear[\"CRIME COUNT\"]), row=2, col=2)\n",
    "fig.add_trace(go.Bar(x=crimes_per_Quarter[\"Quarter\"], y=crimes_per_Quarter[\"CRIME COUNT\"]), row=2, col=3)\n",
    "# Update xaxis properties\n",
    "fig.update_xaxes(title_text=\"Year\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Month\", range=[0, 13], row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Day\", row=1, col=3)\n",
    "fig.update_xaxes(title_text=\"Hour\",row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Weekofyear\", row=2, col=2)\n",
    "fig.update_xaxes(title_text=\"Quarter\", row=2, col=3)\n",
    "# Update yaxis properties\n",
    "fig.update_yaxes(title_text=\"Crime Count\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Crime Count\",row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Crime Count\", row=1, col=3)\n",
    "fig.update_yaxes(title_text=\"Crime Count\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Crime Count\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Crime Count\", row=2, col=3)\n",
    "# Update title\n",
    "fig.update_layout(showlegend=False,title_text=\"Total Crimes in Boston broken down in TIME\", height=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df1.OFFENSE_CODE_GROUP = df1.OFFENSE_CODE_GROUP.astype('category')\n",
    "df1.OFFENSE_DESCRIPTION = df1.OFFENSE_DESCRIPTION.astype('category')\n",
    "df1.DAY_OF_WEEK = df1.DAY_OF_WEEK.astype('category')\n",
    "df1.UCR_PART = df1.UCR_PART.astype('category')\n",
    "df1.DISTRICT = df1.DISTRICT.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_crimes = df1[['MONTH','INCIDENT_NUMBER']].groupby(['MONTH']).count()\n",
    "crimesbyhour = df1[['HOUR','INCIDENT_NUMBER']].groupby(['HOUR']).count()\n",
    "yearly_crimes = df1[['YEAR','INCIDENT_NUMBER']].groupby(['YEAR']).count()\n",
    "crimesbyday = df1[['DAY_OF_WEEK','INCIDENT_NUMBER']].groupby(['DAY_OF_WEEK']).count()\n",
    "crimesbyhour = df1[['HOUR','INCIDENT_NUMBER']].groupby(['HOUR']).count()\n",
    "offenses = df1[['OFFENSE_CODE_GROUP','INCIDENT_NUMBER']].groupby(['OFFENSE_CODE_GROUP']).count()\n",
    "daily_crimes = df1[['OCCURRED_ON_DATE','INCIDENT_NUMBER']].groupby(['OCCURRED_ON_DATE']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crimes by Trend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpldatacursor import datacursor\n",
    "\n",
    "crhour = crimesbyhour.plot(figsize=(15, 5))\n",
    "datacursor(crhour, display='multiple', draggable=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = df1['DISTRICT'].value_counts().head(3).index\n",
    "plt.style.use('bmh')\n",
    "\n",
    "sns.countplot(data = df1, x = 'DISTRICT', hue = 'HOUR', order = sort, palette='rainbow')\n",
    "plt.title('Districts with Highest Crime rates by Hour ')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,8)\n",
    "plt.legend(loc='upper right', prop={'size': 7});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_crimes.plot(figsize=(15, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crime trend matches the Climate trend of Boston 2017, there are more crimes during hotter climates that colder\n",
    "\n",
    "https://weatherspark.com/h/y/26197/2017/Historical-Weather-during-2017-in-Boston-Massachusetts-United-States#Figures-Temperature\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = df1['DISTRICT'].value_counts().head(3).index\n",
    "plt.style.use('bmh')\n",
    "\n",
    "sns.countplot(data = df1, x = 'DISTRICT',  hue = 'MONTH', order = sort, palette='rainbow')\n",
    "plt.title('Districts with Highest Crime rates by MONTH ')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,8)\n",
    "plt.legend(loc='upper right', prop={'size': 7});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_crimes.plot(figsize=(15, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = df1['DISTRICT'].value_counts().head(3).index\n",
    "\n",
    "sns.countplot(data = df1, x = 'DISTRICT', hue = 'YEAR', order = sort, palette='rainbow')\n",
    "plt.title('Districts with Highest Crime rates by YEAR ')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,8)\n",
    "plt.legend(loc='upper right', prop={'size': 7});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(50,18))\n",
    "sns.lineplot(x='OCCURRED_ON_DATE', y='INCIDENT_NUMBER', data=daily_crimes,\n",
    "             ax=ax).set_title(\"Daily Boston Crime numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df1, hue='DISTRICT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys, json\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from requests.exceptions import RequestException\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install geopandas\n",
    "#pip install shapely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use map below to look into specific streets and addresses, this map will allow you to see if a crime happend, when a crime happened and what kind of crime happened. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_map_box = px.scatter_mapbox(df1,\n",
    "                        lat='Lat',\n",
    "                        lon='Long',\n",
    "                        hover_data =['OFFENSE_CODE', 'OFFENSE_DESCRIPTION', 'OCCURRED_ON_DATE'],\n",
    "                        color='OFFENSE_CODE_GROUP',\n",
    "                        #size=\"OFFENSE_CODE\", color_continuous_scale=px.colors.sequential.Rainbow, size_max=100,\n",
    "                        size_max=80,\n",
    "                        zoom = 8,\n",
    "                        mapbox_style='open-street-map')\n",
    "fig_map_box.update_layout(margin={'r':0, 't':0, 'l':0, 'b':0})\n",
    "fig_map_box.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holt Winters' Seasonal Time series Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Your Dataset for Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily_crimes['OCCURRED_ON_DATE'] = pd.to_datetime(df1['OCCURRED_ON_DATE'])\n",
    "# Set the date as index \n",
    "#df2 = df1.set_index('OCCURRED_ON_DATE') -- already set in daily_crimes\n",
    "# Select the proper time period for weekly aggreagation\n",
    "daily_crimes1 = daily_crimes['2015-06-15':'2018-08-26'].resample('W').sum()\n",
    "daily_crimes1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(daily_crimes1, y = 'INCIDENT_NUMBER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "y = daily_crimes1['INCIDENT_NUMBER'] #defining y\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "ax.plot(y,marker='.', linestyle='-', linewidth=0.5, label='Weekly')\n",
    "ax.plot(y.resample('M').mean(),marker='o', markersize=8, linestyle='-', label='Monthly Mean Resample')\n",
    "ax.set_ylabel('Crime Counts')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# graphs to show seasonal_decompose\n",
    "def seasonal_decompose (y):\n",
    "    decomposition = sm.tsa.seasonal_decompose(y, model='additive',extrapolate_trend='freq')\n",
    "    fig = decomposition.plot()\n",
    "    fig.set_size_inches(14,7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_decompose(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Stationarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot for Rolling Statistic for testing Stationarity\n",
    "def test_stationarity(timeseries, title):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.Series(timeseries).rolling(window=12).mean() \n",
    "    rolstd = pd.Series(timeseries).rolling(window=12).std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 4))\n",
    "    ax.plot(timeseries, label= title)\n",
    "    ax.plot(rolmean, label='rolling mean');\n",
    "    ax.plot(rolstd, label='rolling std (x10)');\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.8f}'.format\n",
    "test_stationarity(y,'raw data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller Test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def ADF_test(timeseries, dataDesc):\n",
    "    print(' > Is the {} stationary ?'.format(dataDesc))\n",
    "    dftest = adfuller(timeseries.dropna(), autolag='AIC')\n",
    "    print('Test statistic = {:.3f}'.format(dftest[0]))\n",
    "    print('P-value = {:.3f}'.format(dftest[1]))\n",
    "    print('Critical values :')\n",
    "    for k, v in dftest[4].items():\n",
    "        print('\\t{}: {} - The data is {} stationary with {}% confidence'.format(k, v, 'not' if v<dftest[0] else '', 100-int(k[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF_test(y,'raw data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrending\n",
    "y_detrend =  (y - y.rolling(window=12).mean())/y.rolling(window=12).std()\n",
    "\n",
    "test_stationarity(y_detrend,'de-trended data')\n",
    "ADF_test(y_detrend,'de-trended data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differencing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing\n",
    "y_12lag =  y - y.shift(12)\n",
    "\n",
    "test_stationarity(y_12lag,'12 lag differenced data')\n",
    "ADF_test(y_12lag,'12 lag differenced data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Detrending and Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrending + Differencing\n",
    "\n",
    "y_12lag_detrend =  y_detrend - y_detrend.shift(12)\n",
    "\n",
    "test_stationarity(y_12lag_detrend,'12 lag differenced de-trended data')\n",
    "ADF_test(y_12lag_detrend,'12 lag differenced de-trended data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_to_train = y[:'2018-02-18'] # dataset to train\n",
    "y_to_val = y['2018-02-25':] # last 6 months for test  \n",
    "predict_date = len(y) - len(y[:'2018-02-25']) # the number of data points for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt-Winters’ Seasonal Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing \n",
    "\n",
    "def ses(y, y_to_train,y_to_val,smoothing_level,predict_date):\n",
    "    y.plot(marker='o', color='black', legend=True, figsize=(14, 7))\n",
    "    \n",
    "    fit1 = SimpleExpSmoothing(y_to_train).fit(smoothing_level=smoothing_level,optimized=False)\n",
    "    fcast1 = fit1.forecast(predict_date).rename(r'$\\alpha={}$'.format(smoothing_level))\n",
    "    # specific smoothing level\n",
    "    fcast1.plot(marker='o', color='blue', legend=True)\n",
    "    fit1.fittedvalues.plot(marker='o',  color='blue')\n",
    "    mse1 = ((fcast1 - y_to_val) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of our forecasts with smoothing level of {} is {}'.format(smoothing_level,round(np.sqrt(mse1), 2)))\n",
    "    \n",
    "    ## auto optimization\n",
    "    fit2 = SimpleExpSmoothing(y_to_train).fit()\n",
    "    fcast2 = fit2.forecast(predict_date).rename(r'$\\alpha=%s$'%fit2.model.params['smoothing_level'])\n",
    "    # plot\n",
    "    fcast2.plot(marker='o', color='green', legend=True)\n",
    "    fit2.fittedvalues.plot(marker='o', color='green')\n",
    "    \n",
    "    mse2 = ((fcast2 - y_to_val) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of our forecasts with auto optimization is {}'.format(round(np.sqrt(mse2), 2)))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses(y, y_to_train,y_to_val,0.8,predict_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import Holt\n",
    "\n",
    "def holt(y,y_to_train,y_to_val,smoothing_level,smoothing_slope, predict_date):\n",
    "    y.plot(marker='o', color='black', legend=True, figsize=(14, 7))\n",
    "    \n",
    "    fit1 = Holt(y_to_train).fit(smoothing_level, smoothing_slope, optimized=False)\n",
    "    fcast1 = fit1.forecast(predict_date).rename(\"Holt's linear trend\")\n",
    "    mse1 = ((fcast1 - y_to_val) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of Holt''s Linear trend {}'.format(round(np.sqrt(mse1), 2)))\n",
    "\n",
    "    fit2 = Holt(y_to_train, exponential=True).fit(smoothing_level, smoothing_slope, optimized=False)\n",
    "    fcast2 = fit2.forecast(predict_date).rename(\"Exponential trend\")\n",
    "    mse2 = ((fcast2 - y_to_val) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of Holt''s Exponential trend {}'.format(round(np.sqrt(mse2), 2)))\n",
    "    \n",
    "    fit1.fittedvalues.plot(marker=\"o\", color='blue')\n",
    "    fcast1.plot(color='blue', marker=\"o\", legend=True)\n",
    "    fit2.fittedvalues.plot(marker=\"o\", color='red')\n",
    "    fcast2.plot(color='red', marker=\"o\", legend=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holt(y, y_to_train,y_to_val,0.6,0.2,predict_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "def holt_win_sea(y,y_to_train,y_to_val,seasonal_type,seasonal_period,predict_date):\n",
    "    \n",
    "    y.plot(marker='o', color='black', legend=True, figsize=(14, 7))\n",
    "    \n",
    "    if seasonal_type == 'additive':\n",
    "        fit1 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='add').fit(use_boxcox=True)\n",
    "        fcast1 = fit1.forecast(predict_date).rename('Additive')\n",
    "        mse1 = ((fcast1 - y_to_val) ** 2).mean()\n",
    "        print('The Root Mean Squared Error of additive trend, additive seasonal of '+ \n",
    "              'period season_length={} and a Box-Cox transformation {}'.format(seasonal_period,round(np.sqrt(mse1), 2)))\n",
    "        \n",
    "        fit2 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='add', damped=True).fit(use_boxcox=True)\n",
    "        fcast2 = fit2.forecast(predict_date).rename('Additive+damped')\n",
    "        mse2 = ((fcast2 - y_to_val) ** 2).mean()\n",
    "        print('The Root Mean Squared Error of additive damped trend, additive seasonal of '+ \n",
    "              'period season_length={} and a Box-Cox transformation {}'.format(seasonal_period,round(np.sqrt(mse2), 2)))\n",
    "        \n",
    "        fit1.fittedvalues.plot(style='--', color='red')\n",
    "        fcast1.plot(style='--', marker='o', color='red', legend=True)\n",
    "        fit2.fittedvalues.plot(style='--', color='green')\n",
    "        fcast2.plot(style='--', marker='o', color='green', legend=True)\n",
    "    \n",
    "    elif seasonal_type == 'multiplicative':  \n",
    "        fit3 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='mul').fit(use_boxcox=True)\n",
    "        fcast3 = fit3.forecast(predict_date).rename('Multiplicative')\n",
    "        mse3 = ((fcast3 - y_to_val) ** 2).mean()\n",
    "        print('The Root Mean Squared Error of additive trend, multiplicative seasonal of '+ \n",
    "              'period season_length={} and a Box-Cox transformation {}'.format(seasonal_period,round(np.sqrt(mse3), 2)))\n",
    "        \n",
    "        fit4 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='mul', damped=True).fit(use_boxcox=True)\n",
    "        fcast4 = fit4.forecast(predict_date).rename('Multiplicative+damped')\n",
    "        mse4 = ((fcast3 - y_to_val) ** 2).mean()\n",
    "        print('The Root Mean Squared Error of additive damped trend, multiplicative seasonal of '+ \n",
    "              'period season_length={} and a Box-Cox transformation {}'.format(seasonal_period,round(np.sqrt(mse4), 2)))\n",
    "        \n",
    "        fit3.fittedvalues.plot(style='--', color='red')\n",
    "        fcast3.plot(style='--', marker='o', color='red', legend=True)\n",
    "        fit4.fittedvalues.plot(style='--', color='green')\n",
    "        fcast4.plot(style='--', marker='o', color='green', legend=True)\n",
    "        \n",
    "    else:\n",
    "        print('Wrong Seasonal Type. Please choose between additive and multiplicative')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holt_win_sea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Prophet installation this doesn't work anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holt_win_sea(y, y_to_train,y_to_val,'additive',52, predict_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_crimes2 = daily_crimes\n",
    "daily_crimes2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_crimes2 = daily_crimes['2015-06-15':'2018-08-26'].resample('W').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_crimes2 = daily_crimes2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for Items sold over time\n",
    "#daily_crimes2.index.rename('ds', inplace=True)\n",
    "daily_crimes2.rename(columns={'INCIDENT_NUMBER': 'y'}, inplace=True)\n",
    "daily_crimes2.rename(columns={'OCCURRED_ON_DATE': 'ds'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_crimes2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and 'fit' (train) the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('fbprophet').setLevel(logging.WARNING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.fit(daily_crimes2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods=365)\n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet Visualization of results : Prediction of Crimes in Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "fig = plot_plotly(m, forecast)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to see the components of the forecast, we can use the Prophet.plot_components method. By default, you will see the trend, the annual seasonality and the weekly seasonality of the time series. If holidays are included, they will also appear on the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_components_plotly(m, forecast)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add holiday date information to Peyton's forecast, since we hypothesize changes in crime rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.add_country_holidays(country_name='US')\n",
    "m.fit(daily_crimes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.train_holiday_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(future)\n",
    "fig = plot_components_plotly(m, forecast)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Order of Seasonalities\n",
    "Seasonalities are estimated using a partial Fourier sum. The number of terms in the partial sum(the order) is a parameter that determines how quickly the seasonality can change.\n",
    "\n",
    "\n",
    "The default Fourier order for yearly seasonality is 10. The default values are often appropriate, but they can be increased when the seasonality needs to fit higher-frequency changes, and generally be less smooth. The Fourier order can be specified for each built-in seasonality when instantiating the model, here it is increased to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.plot import plot_yearly\n",
    "m_yearly = Prophet(yearly_seasonality=20).fit(daily_crimes2)\n",
    "a = plot_yearly(m_yearly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# CONCLUSIONS : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process :\n",
    "* Data consists of the the following: \n",
    "\t* Index(['INCIDENT_NUMBER', 'OFFENSE_CODE', 'OFFENSE_CODE_GROUP',\n",
    "       'OFFENSE_DESCRIPTION', 'DISTRICT', 'REPORTING_AREA', 'SHOOTING',\n",
    "       'OCCURRED_ON_DATE', 'YEAR', 'MONTH', 'DAY_OF_WEEK', 'HOUR', 'UCR_PART',\n",
    "       'STREET', 'Lat', 'Long', 'Location', 'Quarter', 'Weekofyear'],\n",
    "\n",
    "* Data Quality : \n",
    "\t* MSNO Matrix shows the following Columns had NULL values : 'SHOOTING','DISTRICT', 'STREET', 'Lat' and 'Long'. 'INCIDENT_NUMBER', also had duplicates that needed cleaning\n",
    "\n",
    "* Date Range : June 2015 to Sep 2018\n",
    "\n",
    "\n",
    "Predictions :\n",
    "\n",
    "*      Seasonality patterns from Jul 2018 to Jul 2019 will observe the same patterns as previous years but slightly lower in value. \n",
    "*      Foreseen spikes in Crime during New Year's and Drops during Christmas\n",
    "*      Overall reduction towards July 2019\n",
    "\n",
    "Conclusions\n",
    "LOCATION, DISTRICT \n",
    "* -Top 3 Districts with the highest crime counts would be B2, C11, D4.\n",
    "* -Top Crime in B2 and C11 is Motor Vehicle Accident Response while Top Crime in D4 is Larceny\n",
    "* -Different districts may have different peak crime days within the week, for example : looking at the top 5 districts the peaks happen within the following days\n",
    "*\t\t-B2 - Wednesday, Thursday to Fridays \n",
    "*\t\t-C11 - Mondays, Tuesdays and Wednesdays\n",
    "*\t\t-D4 -Friday and Wednesday\n",
    "*\t\t-B3 - Mondays, Tuesdays and Wednesdays\n",
    "*\t\t-A1- Friday and Saturdays\n",
    "* Sunday is seen to be consistently low across all TOP 5 Districts\n",
    "\t\n",
    "CRIMES with Shootings\n",
    "*  \t-Only 0.22 percent of the crimes have associated SHOOTINGS\n",
    "*\t-Highest number of Shootings happen in Districts B2 C11 and B3\n",
    "*\t-Crime Groups with Highest shootings are Aggrevated Assault and Homicide\n",
    "\n",
    "UCR Parts\n",
    "*\t-Highest UCR part is Part 3 and Lowest is Other followed by Part 1. \n",
    "*\t-UCR Parts are equally disctributed through the different days\n",
    "\n",
    "\n",
    "CRIME Types \n",
    "* -Top crime in Boston is Motor Vehicle Accident Response which consists of 11.64 percent all crimes\n",
    "*\t-8 percent goes to Larceny\n",
    "*\t-7.38 percent falls under the offense code group of Medical assistance (there is an opportunity to define cause of Medical assistance related to a specific offense)\n",
    "\n",
    "TIME (Year, Month, Day of the week, Hour, Week of the year, Quarter)\n",
    "* In General: \n",
    "* Year, Graph shows a higher Crime count in 2017 compared to 2016, 2015 and 2018 however does not contain a full year's worth of data to make any assumptions\n",
    "* Month, Highest crime counts occured July and August while the lowest was in February \n",
    "*             - The Crime rate seems to follow the same trend line as Boston's climate \n",
    "*             https://weatherspark.com/y/26197/Average-Weather-in-Boston-Massachusetts-United-States-Year-Round#Figures-Temperature\n",
    "* Day of the week,\n",
    "*\t-Crime increases drastically from Thursday to Friday, Friday having the highest crime count while it drastically drops during the weekend, Sunday having the lowest crime count. \n",
    "* Hour, the hours with the highest crime rates are 15h, 16h, 17h being the highest, and 18h then drops from there until another crime spike at midnight. Lowest crime counts happen between 4am to 6am.\n",
    "* Week of the year, For weekly planning of task force deployment; the Boston department can note that the weeks with the highest crime rates are between week 25 and week 35, the lowest crime happens on week 6 not counting the leap years\n",
    "* Quarter 3 has the Highest Crime rate while Quarter 1 has the lowest\n",
    "\n",
    "TIME versus DISTRICT 3 Districts\n",
    "*\t-Hour, The trend of crime generally follows the overall trend except for District B2 not seeing an increas during 12nn.\n",
    "*\t-Year and Month are aligned with overall trend\n",
    "*\t-Day of the Week crime counts may vary per district as shown in District analysis conclusion\n",
    "\n",
    "CRIME TYPE ON THE MAP\n",
    "* There is an available Map that lets you zoom into the streets and see and filter specific crime types\n",
    "* There is no visual concentration of specific crime types plotted on the map \n",
    "\n",
    "PREDICTIONS : (additional KMEANS attempt below)\n",
    "* Looking at the data showing seasonality in crime trends with Boston's climate\n",
    "* Using Holt-Winters’ Seasonal Method, prediction falls under an additive type of seasonality. \n",
    "*      \tAdditive: xt = Trend + Seasonal + Random\n",
    "*      \tSeasonal changes in the data stay roughly the same over time and don’t fluctuate in relation to the overall data.\n",
    "\n",
    "* Chart shows a slight decrease in crime rates contributed from seasonality. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Model\n",
    "TRYING KMEANS ON TOP 20 percent OF CRIME TYPES \n",
    "* This activity is to see if there are any clusters of top 20 percent of crimes that can relate to weeks of the year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "District = df1['DISTRICT'].value_counts(dropna=np.False_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "District = pd.DataFrame(District)\n",
    "District.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "District = District.rename(columns={'index':'district'})\n",
    "District = District.rename(columns={'DISTRICT':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offense_type = df1['OFFENSE_CODE_GROUP'].value_counts(dropna=np.False_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offense_type = pd.DataFrame(Offense_type)\n",
    "Offense_type.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Offense_type = Offense_type.rename(columns={'index':'Offense'})\n",
    "Offense_type = Offense_type.rename(columns={'OFFENSE_CODE_GROUP':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Offense_type = Offense_type.rename(columns={'Offense_type':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown of Districts and Offense Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a groupby DataFrame by DISTRICT\n",
    "DISTRICT_pivot = df1.groupby([\"DISTRICT\"]).size()\\\n",
    ".sort_values(ascending = False).to_frame().reset_index().rename(columns = {0: \"offenses_per_district\"})\n",
    "\n",
    "DISTRICT_pivot[\"cumsum_by_district\"] = (DISTRICT_pivot[\"offenses_per_district\"]/DISTRICT_pivot[\"offenses_per_district\"].sum()).cumsum()\n",
    "\n",
    "DISTRICT_pivot[\"pct_district\"] = (1/DISTRICT_pivot.shape[0])\n",
    "DISTRICT_pivot[\"pct_district\"] = DISTRICT_pivot[\"pct_district\"].cumsum()\n",
    "DISTRICT_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a groupby DataFrame by OFFENSE TYPE\n",
    "OFFENSE_pivot = df1.groupby([\"OFFENSE_CODE_GROUP\"]).size()\\\n",
    ".sort_values(ascending = False).to_frame().reset_index().rename(columns = {0: \"offenses_per_group\"})\n",
    "\n",
    "OFFENSE_pivot[\"cumsum_by_type\"] = (OFFENSE_pivot[\"offenses_per_group\"]/OFFENSE_pivot[\"offenses_per_group\"].sum()).cumsum()\n",
    "\n",
    "OFFENSE_pivot[\"pct_type\"] = (1/OFFENSE_pivot.shape[0])\n",
    "OFFENSE_pivot[\"pct_type\"] = OFFENSE_pivot[\"pct_type\"].cumsum()\n",
    "OFFENSE_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------\n",
    "# Plotting part\n",
    "\n",
    "# Instantiate the figure\n",
    "fig = plt.figure(figsize = (10, 15))\n",
    "ax1, ax2, ax3 = fig.subplots(nrows = 3, ncols = 1)\n",
    "\n",
    "# get the data\n",
    "# concate a zero before the list, so that all curves start at origin\n",
    "x1_values = [0] + list(DISTRICT_pivot.index)\n",
    "y1_values = [0] + list(DISTRICT_pivot[\"cumsum_by_district\"])\n",
    "\n",
    "x2_values = [0] + list(OFFENSE_pivot[\"cumsum_by_type\"])\n",
    "y2_values = [0] + list(OFFENSE_pivot[\"cumsum_by_type\"])\n",
    "\n",
    "x3_values_District = [0] + list(DISTRICT_pivot[\"pct_district\"])\n",
    "y3_values_District = [0] + list(DISTRICT_pivot[\"cumsum_by_district\"])\n",
    "\n",
    "x3_values_type = [0] + list(OFFENSE_pivot[\"pct_type\"])\n",
    "y3_values_type = [0] + list(OFFENSE_pivot[\"cumsum_by_type\"])\n",
    "\n",
    "# plot the values and set for every subplot a title\n",
    "ax1.plot(y1_values)\n",
    "ax1.title.set_text(\"Percentage of Accumulated Crime counts  by District\")\n",
    "\n",
    "ax2.plot(y2_values, color = \"green\", alpha = 0.5)\n",
    "ax2.title.set_text(\"Percentage of Accumulated Crime counts  by Offense Type\")\n",
    "\n",
    "ax3.plot(x3_values_District, y3_values_District, label = \"Percentage of Accumulated Crime counts  by District\")\n",
    "ax3.plot(x3_values_type, y3_values_type, label = \"Percentage of Accumulated Crime counts  by Offense Type\", \n",
    "         color = \"green\", alpha = 0.5)\n",
    "ax3.title.set_text(\"Percentage of Accumulated Crime counts  by District and Offense Type\")\n",
    "\n",
    "ax3.legend()\n",
    "\n",
    "# create a title for the figure\n",
    "fig.suptitle('Cumulative distribution of Crime counts by District and Offense Type (absolute and relative)', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crimes per district don't show q significant concentration in one are\n",
    "\n",
    "Crimes by Type shows a significant concentration in one are - Based on pareto principles a in depth look can be done on 20 percent of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMEANS CLUSTERING DATA focusing on 20 percent the problem - Crime Type Group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "\n",
    "data_pivot = df1.pivot_table(index='Weekofyear', columns='DISTRICT',\n",
    "  aggfunc=len, fill_value=0)\n",
    "data2_pivot = df1.pivot_table(index='Weekofyear', columns='OFFENSE_CODE_GROUP',\n",
    "  aggfunc=len, fill_value=0)\n",
    "all_data = pd.merge(data_pivot, data2_pivot, on = [\"Weekofyear\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattten multiple index pivots\n",
    "all_data.columns = all_data.columns.to_flat_index().str.join('_')\n",
    "all_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_clusters = all_data[['YEAR_Motor Vehicle Accident Response','YEAR_Larceny','Weekofyear']]\n",
    "district_clusters.columns = district_clusters.columns.str.replace('YEAR_Motor Vehicle Accident Response', 'Vehicle_Accident_Response')\n",
    "district_clusters.columns = district_clusters.columns.str.replace('YEAR_Larceny', 'Larceny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_clusters = district_clusters.drop([52])\n",
    "district_clusters.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_clusters.drop(district_clusters.index[district_clusters['Weekofyear'] == 53], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x = district_clusters['Vehicle_Accident_Response'], y = district_clusters['Larceny'], title = 'Original Variables' )\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,RobustScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(district_clusters.to_numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x = scaled_data[:,0], y = scaled_data[:,1], title = 'Standarised Variables' )\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = kmeans.predict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x = scaled_data[:,0], y = scaled_data[:,1], color = prediction, title = 'Scaled Variables' )\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x =  district_clusters['Vehicle_Accident_Response'], y =  district_clusters['Larceny'], color = prediction, title = 'Original Variables' )\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.scatter(pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_)), x=0, y=1, title='Cluster Centers')\n",
    "fig2.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversed = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "inversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x = scaled_data[:,0], y = scaled_data[:,1], color = prediction )\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "fig2 = px.scatter(pd.DataFrame(kmeans.cluster_centers_), x=0, y=1)\n",
    "fig2.update_traces(marker=dict(size=20, color='pink', line=dict(width=2, color='white')), selector=dict(mode='markers'), marker_symbol = 'x')\n",
    "\n",
    "fig.add_trace(fig2.data[0])\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x =  district_clusters['Vehicle_Accident_Response'], y =  district_clusters['Larceny'], color = prediction )\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "fig2 = px.scatter(pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_)), x=0, y=1)\n",
    "fig2.update_traces(marker=dict(size=20, color='pink', line=dict(width=2, color='white')), selector=dict(mode='markers'), marker_symbol = 'x')\n",
    "\n",
    "fig.add_trace(fig2.data[0])\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.predict([[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 700\n",
    "y1 = 700\n",
    "z1 = 700\n",
    "kmeans.predict(scaler.transform([[x1,y1,z1]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x =  district_clusters['Vehicle_Accident_Response'], y =  district_clusters['Larceny'], color = prediction )\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "fig2 = px.scatter(pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_)), x=0, y=1)\n",
    "fig2.update_traces(marker=dict(size=20, color='pink', line=dict(width=2, color='white')), selector=dict(mode='markers'), marker_symbol = 'x')\n",
    "fig.add_shape(type=\"circle\", xref=\"x\", yref=\"y\", x0=x1+0.1, y0=y1+0.15, x1=x1, y1=y1, line_color=\"green\",fillcolor = 'green')\n",
    "\n",
    "\n",
    "fig.add_trace(fig2.data[0])\n",
    "fig.update_layout(template = 'plotly_white')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x =  district_clusters['Vehicle_Accident_Response'], y =  district_clusters['Larceny'], color = prediction, symbol = district_clusters['Weekofyear'] )\n",
    "fig.update_traces(marker=dict(size=12, line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\n",
    "fig2 = px.scatter(pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_)), x=0, y=1)\n",
    "fig2.update_traces(marker=dict(size=20, color='pink', line=dict(width=2, color='white')), selector=dict(mode='markers'), marker_symbol = 'x')\n",
    "fig.add_shape(type=\"circle\", xref=\"x\", yref=\"y\", x0=x1+0.1, y0=y1+0.15, x1=x1, y1=y1, line_color=\"green\",fillcolor = 'green')\n",
    "fig.update_layout(legend_orientation=\"h\")\n",
    "\n",
    "\n",
    "fig.add_trace(fig2.data[0])\n",
    "fig.update_layout(template = 'plotly_white')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "* CLUSTERS in Yellow are TOP Spikes for both Larceny and Vehicle Assistance Response happening on the following weeks : 25 to 35."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6c67bf228ca0434dcb31b7fb7a31ec7054962b22b102900a93293c506a05e4c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
